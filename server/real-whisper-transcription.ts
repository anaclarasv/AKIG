import nodeWhisper from 'node-whisper';
import fs from 'fs';
import path from 'path';

export class RealWhisperTranscription {
  private static transcriptionCache = new Map<string, any>();
  private static processingStatus = new Map<string, any>();

  /**
   * Transcreve √°udio usando Whisper local real
   */
  static async transcribeAudio(audioFilePath: string): Promise<any> {
    console.log('Iniciando transcri√ß√£o real com Whisper para:', audioFilePath);
    
    const cacheKey = audioFilePath;
    if (this.transcriptionCache.has(cacheKey)) {
      console.log('Retornando transcri√ß√£o do cache');
      return this.transcriptionCache.get(cacheKey);
    }

    // Verificar se arquivo existe
    if (!fs.existsSync(audioFilePath)) {
      throw new Error(`Arquivo de √°udio n√£o encontrado: ${audioFilePath}`);
    }

    try {
      // Marcar como processando
      this.processingStatus.set(cacheKey, { status: 'processing', progress: 10 });

      console.log('Executando Whisper com configura√ß√µes em portugu√™s...');
      
      // Atualizar status
      this.processingStatus.set(cacheKey, { status: 'processing', progress: 30 });

      // Executar transcri√ß√£o real com configura√ß√£o simples
      const startTime = Date.now();
      
      // Usar a API correta do node-whisper
      const transcript = await nodeWhisper(audioFilePath);
      
      const endTime = Date.now();
      const processingTime = (endTime - startTime) / 1000;
      
      console.log(`‚úÖ Transcri√ß√£o conclu√≠da em ${processingTime}s`);
      
      // Atualizar status
      this.processingStatus.set(cacheKey, { status: 'processing', progress: 80 });

      // Processar resultado
      const result = this.processWhisperResult(transcript, audioFilePath);
      
      // Cache do resultado
      this.transcriptionCache.set(cacheKey, result);
      
      // Marcar como conclu√≠do
      this.processingStatus.set(cacheKey, { status: 'completed', progress: 100 });
      
      console.log('üìù Texto transcrito:', result.text.substring(0, 100) + '...');
      return result;

    } catch (error) {
      console.error('‚ùå Erro na transcri√ß√£o Whisper:', error);
      this.processingStatus.set(cacheKey, { 
        status: 'error', 
        progress: 0, 
        error: error.message 
      });
      throw error;
    }
  }

  /**
   * Processa o resultado do Whisper para o formato esperado
   */
  private static processWhisperResult(transcript: any, audioFilePath: string): any {
    console.log('üîÑ Processando resultado do Whisper...');
    
    // Obter dura√ß√£o do √°udio
    const stats = fs.statSync(audioFilePath);
    const estimatedDuration = this.estimateAudioDuration(stats.size);
    
    let segments = [];
    let fullText = '';

    if (transcript && typeof transcript === 'object') {
      // Se o Whisper retornou segmentos com timestamps
      if (transcript.segments && Array.isArray(transcript.segments)) {
        segments = transcript.segments.map((segment: any, index: number) => ({
          id: `seg_${index + 1}`,
          speaker: this.detectSpeaker(segment.text, index),
          text: segment.text.trim(),
          startTime: segment.start || (index * 5),
          endTime: segment.end || ((index + 1) * 5),
          confidence: segment.confidence || 0.9
        }));
        fullText = transcript.segments.map((s: any) => s.text).join(' ');
      } else if (transcript.text) {
        // Se retornou apenas texto
        fullText = transcript.text;
        segments = this.createSegmentsFromText(fullText, estimatedDuration);
      }
    } else if (typeof transcript === 'string') {
      // Se retornou string direta
      fullText = transcript;
      segments = this.createSegmentsFromText(fullText, estimatedDuration);
    }

    return {
      text: fullText,
      segments,
      duration: estimatedDuration,
      transcriptionMethod: 'whisper_local',
      isAuthentic: true,
      processingTime: 'real',
      confidence: 0.9
    };
  }

  /**
   * Cria segmentos a partir de texto quando n√£o h√° timestamps
   */
  private static createSegmentsFromText(text: string, duration: number): any[] {
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    const segmentDuration = duration / sentences.length;
    
    return sentences.map((sentence, index) => ({
      id: `seg_${index + 1}`,
      speaker: this.detectSpeaker(sentence, index),
      text: sentence.trim(),
      startTime: index * segmentDuration,
      endTime: (index + 1) * segmentDuration,
      confidence: 0.9
    }));
  }

  /**
   * Detecta falante b√°sico baseado no conte√∫do
   */
  private static detectSpeaker(text: string, index: number): string {
    const agentKeywords = ['posso ajudar', 'obrigad', 'aqui √©', 'vou verificar', 'empresa'];
    const clientKeywords = ['preciso', 'problema', 'quero', 'gostaria', 'n√£o consigo'];
    
    const lowerText = text.toLowerCase();
    
    if (agentKeywords.some(keyword => lowerText.includes(keyword))) {
      return 'agent';
    } else if (clientKeywords.some(keyword => lowerText.includes(keyword))) {
      return 'client';
    }
    
    // Altern√¢ncia simples se n√£o conseguir detectar
    return index % 2 === 0 ? 'agent' : 'client';
  }

  /**
   * Estima dura√ß√£o do √°udio baseado no tamanho do arquivo
   */
  private static estimateAudioDuration(fileSize: number): number {
    // Estimativa aproximada: 1MB ‚âà 60 segundos para MP3 de qualidade m√©dia
    const estimatedSeconds = Math.max(30, fileSize / 17000);
    return Math.min(900, estimatedSeconds); // M√°ximo 15 minutos
  }

  /**
   * Verifica status da transcri√ß√£o
   */
  static getTranscriptionStatus(audioFilePath: string): any {
    return this.processingStatus.get(audioFilePath) || { status: 'not_found' };
  }

  /**
   * Limpa cache
   */
  static clearCache(): void {
    this.transcriptionCache.clear();
    this.processingStatus.clear();
    console.log('üßπ Cache de transcri√ß√µes limpo');
  }

  /**
   * An√°lise b√°sica do texto transcrito
   */
  static analyzeTranscription(transcriptionResult: any): any {
    const { text, segments } = transcriptionResult;
    
    // An√°lise de sentimento
    const positiveWords = ['obrigado', 'excelente', '√≥timo', 'bom', 'perfeito'];
    const negativeWords = ['problema', 'erro', 'ruim', 'dificuldade', 'n√£o funciona'];
    
    const positiveCount = positiveWords.filter(word => 
      text.toLowerCase().includes(word)
    ).length;
    
    const negativeCount = negativeWords.filter(word => 
      text.toLowerCase().includes(word)
    ).length;
    
    const sentiment = positiveCount > negativeCount ? 0.7 : 0.4;
    
    return {
      sentiment,
      tone: 0.7,
      criticalWordsCount: negativeCount,
      positiveIndicators: positiveCount,
      overallScore: Math.min(10, 5 + (sentiment * 5)),
      recommendations: negativeCount > 2 ? 
        ['Melhorar abordagem com cliente', 'Focar em solu√ß√µes r√°pidas'] :
        ['Atendimento adequado', 'Manter padr√£o de qualidade'],
      analysisMethod: 'whisper_nlp'
    };
  }
}